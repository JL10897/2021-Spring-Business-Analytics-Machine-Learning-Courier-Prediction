{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python377jvsc74a57bd0cb421fcbfbaf0104cacf837c3c93e5a1272efcec6efbfe33617a554fafda64f9",
   "display_name": "Python 3.7.7 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "cb421fcbfbaf0104cacf837c3c93e5a1272efcec6efbfe33617a554fafda64f9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# 1 Classification\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Step 1: Preparing Data "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import sklearn\n",
    "import scipy as sp\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataframe_train.csv')\n",
    "df_p=pd.read_csv('dataframe_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['courier_id', 'wave_index', 'tracking_id', 'date', 'aoi_id', 'shop_id', 'id', 'source_type', 'source_tracking_id', 'expected_use_time']\n"
     ]
    }
   ],
   "source": [
    "# for df\n",
    "columns_all=df.columns.values\n",
    "columns_need=['grid_distance','target_lng','target_lat','action_type','weather_grade','courier_wave_start_lng','courier_wave_start_lat','group','level','speed','max_load','urgency','hour','source_lng','source_lat']\n",
    "columns_to_drop=[]\n",
    "for i in columns_all:\n",
    "    if i not in columns_need:\n",
    "        columns_to_drop.append(i)\n",
    "print(columns_to_drop)\n",
    "df=df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['courier_id', 'wave_index', 'tracking_id', 'date', 'aoi_id', 'shop_id', 'id', 'source_type', 'source_tracking_id']\n"
     ]
    }
   ],
   "source": [
    "#for df_p\n",
    "columns_all=df_p.columns.values\n",
    "\n",
    "columns_need=['grid_distance','target_lng','target_lat','action_type','weather_grade','courier_wave_start_lng','courier_wave_start_lat','group','level','speed','max_load','urgency','hour','source_lng','source_lat']\n",
    "columns_to_drop=[]\n",
    "for i in columns_all:\n",
    "    if i not in columns_need:\n",
    "        columns_to_drop.append(i)\n",
    "print(columns_to_drop)\n",
    "df_p=df_p.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 509604 entries, 0 to 509603\n",
      "Data columns (total 15 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   courier_wave_start_lng  509604 non-null  float64\n",
      " 1   courier_wave_start_lat  509604 non-null  float64\n",
      " 2   action_type             509604 non-null  object \n",
      " 3   group                   509604 non-null  float64\n",
      " 4   level                   509604 non-null  int64  \n",
      " 5   speed                   509604 non-null  float64\n",
      " 6   max_load                509604 non-null  int64  \n",
      " 7   weather_grade           509604 non-null  object \n",
      " 8   source_lng              509604 non-null  float64\n",
      " 9   source_lat              509604 non-null  float64\n",
      " 10  target_lng              509604 non-null  float64\n",
      " 11  target_lat              509604 non-null  float64\n",
      " 12  grid_distance           509604 non-null  float64\n",
      " 13  urgency                 509604 non-null  int64  \n",
      " 14  hour                    509604 non-null  int64  \n",
      "dtypes: float64(9), int64(4), object(2)\n",
      "memory usage: 58.3+ MB\n",
      "None\n",
      "   courier_wave_start_lng  courier_wave_start_lat action_type         group  \\\n",
      "0              121.630997               39.142343      PICKUP  2.020020e+16   \n",
      "1              121.630997               39.142343    DELIVERY  2.020020e+16   \n",
      "2              121.630997               39.142343      PICKUP  2.020020e+16   \n",
      "3              121.630997               39.142343    DELIVERY  2.020020e+16   \n",
      "4              121.630997               39.142343      PICKUP  2.020020e+16   \n",
      "\n",
      "   level     speed  max_load   weather_grade  source_lng  source_lat  \\\n",
      "0      3  4.751832        11  Normal Weather  121.630997   39.142343   \n",
      "1      3  4.751832        11  Normal Weather  121.632547   39.141946   \n",
      "2      3  4.751832        11  Normal Weather  121.626144   39.140281   \n",
      "3      3  4.751832        11  Normal Weather  121.631219   39.141811   \n",
      "4      3  4.751832        11  Normal Weather  121.632084   39.146201   \n",
      "\n",
      "   target_lng  target_lat  grid_distance  urgency  hour  \n",
      "0  121.632547   39.141946          377.0     1246    11  \n",
      "1  121.626144   39.140281          780.0     1246    11  \n",
      "2  121.631219   39.141811          550.0     2462    11  \n",
      "3  121.632084   39.146201          707.0     1205    11  \n",
      "4  121.631574   39.142231          770.0     1882    11  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25468 entries, 0 to 25467\n",
      "Data columns (total 14 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   courier_wave_start_lng  25468 non-null  float64\n",
      " 1   courier_wave_start_lat  25468 non-null  float64\n",
      " 2   group                   25468 non-null  float64\n",
      " 3   level                   25468 non-null  int64  \n",
      " 4   speed                   25468 non-null  float64\n",
      " 5   max_load                25468 non-null  int64  \n",
      " 6   weather_grade           25468 non-null  object \n",
      " 7   source_lng              25468 non-null  float64\n",
      " 8   source_lat              25468 non-null  float64\n",
      " 9   target_lng              25468 non-null  float64\n",
      " 10  target_lat              25468 non-null  float64\n",
      " 11  grid_distance           25468 non-null  float64\n",
      " 12  urgency                 25468 non-null  int64  \n",
      " 13  hour                    25468 non-null  int64  \n",
      "dtypes: float64(9), int64(4), object(1)\n",
      "memory usage: 2.7+ MB\n",
      "None\n",
      "   courier_wave_start_lng  courier_wave_start_lat         group  level  \\\n",
      "0              121.630558                 39.1409  2.020000e+16      3   \n",
      "1              121.630558                 39.1409  2.020000e+16      3   \n",
      "2              121.630558                 39.1409  2.020000e+16      3   \n",
      "3              121.630558                 39.1409  2.020000e+16      3   \n",
      "4              121.630558                 39.1409  2.020000e+16      3   \n",
      "\n",
      "      speed  max_load   weather_grade  source_lng  source_lat  target_lng  \\\n",
      "0  5.535851        11  Normal Weather  121.630558   39.140900  121.629930   \n",
      "1  5.535851        11  Normal Weather  121.629930   39.144603  121.629604   \n",
      "2  5.535851        11  Normal Weather  121.629604   39.150661  121.629930   \n",
      "3  5.535851        11  Normal Weather  121.629930   39.144603  121.630544   \n",
      "4  5.535851        11  Normal Weather  121.630544   39.152711  121.631446   \n",
      "\n",
      "   target_lat  grid_distance  urgency  hour  \n",
      "0   39.144603          796.0     1776    13  \n",
      "1   39.150661         1048.0      697    13  \n",
      "2   39.144603         1019.0     1756    13  \n",
      "3   39.152711         1198.0      676    13  \n",
      "4   39.142762         1275.0     2336    14  \n"
     ]
    }
   ],
   "source": [
    "print(df.info())\n",
    "print(df.head())\n",
    "print(df_p.info())\n",
    "print(df_p.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 509604 entries, 0 to 509603\nData columns (total 17 columns):\n #   Column                              Non-Null Count   Dtype  \n---  ------                              --------------   -----  \n 0   courier_wave_start_lng              509604 non-null  float64\n 1   courier_wave_start_lat              509604 non-null  float64\n 2   group                               509604 non-null  float64\n 3   level                               509604 non-null  int64  \n 4   speed                               509604 non-null  float64\n 5   max_load                            509604 non-null  int64  \n 6   source_lng                          509604 non-null  float64\n 7   source_lat                          509604 non-null  float64\n 8   target_lng                          509604 non-null  float64\n 9   target_lat                          509604 non-null  float64\n 10  grid_distance                       509604 non-null  float64\n 11  urgency                             509604 non-null  int64  \n 12  hour                                509604 non-null  int64  \n 13  action_type_PICKUP                  509604 non-null  uint8  \n 14  weather_grade_Normal Weather        509604 non-null  uint8  \n 15  weather_grade_Slightly Bad Weather  509604 non-null  uint8  \n 16  weather_grade_Very Bad Weather      509604 non-null  uint8  \ndtypes: float64(9), int64(4), uint8(4)\nmemory usage: 52.5 MB\nNone\n<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25468 entries, 0 to 25467\nData columns (total 16 columns):\n #   Column                              Non-Null Count  Dtype  \n---  ------                              --------------  -----  \n 0   courier_wave_start_lng              25468 non-null  float64\n 1   courier_wave_start_lat              25468 non-null  float64\n 2   group                               25468 non-null  float64\n 3   level                               25468 non-null  int64  \n 4   speed                               25468 non-null  float64\n 5   max_load                            25468 non-null  int64  \n 6   source_lng                          25468 non-null  float64\n 7   source_lat                          25468 non-null  float64\n 8   target_lng                          25468 non-null  float64\n 9   target_lat                          25468 non-null  float64\n 10  grid_distance                       25468 non-null  float64\n 11  urgency                             25468 non-null  int64  \n 12  hour                                25468 non-null  int64  \n 13  weather_grade_Normal Weather        25468 non-null  uint8  \n 14  weather_grade_Slightly Bad Weather  25468 non-null  uint8  \n 15  weather_grade_Very Bad Weather      25468 non-null  uint8  \ndtypes: float64(9), int64(4), uint8(3)\nmemory usage: 2.6 MB\nNone\n"
     ]
    }
   ],
   "source": [
    "df=pd.get_dummies(df,columns=['action_type','weather_grade'],drop_first=True)\n",
    "# df=pd.get_dummies(df,columns=['source_type'],drop_first=True)\n",
    "df_p=pd.get_dummies(df_p,columns=['weather_grade'],drop_first=True)\n",
    "print(df.info())\n",
    "print(df_p.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tr_te_split\n",
    "X = df.drop(columns=['action_type_PICKUP'])\n",
    "y = df['action_type_PICKUP'].ravel()\n",
    "X_train, X_test, y_train, y_test = tr_te_split(X, y, test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   courier_wave_start_lng  courier_wave_start_lat         group  level  \\\n",
       "0              121.630997               39.142343  2.020020e+16      3   \n",
       "1              121.630997               39.142343  2.020020e+16      3   \n",
       "2              121.630997               39.142343  2.020020e+16      3   \n",
       "3              121.630997               39.142343  2.020020e+16      3   \n",
       "4              121.630997               39.142343  2.020020e+16      3   \n",
       "\n",
       "      speed  max_load  source_lng  source_lat  target_lng  target_lat  \\\n",
       "0  4.751832        11  121.630997   39.142343  121.632547   39.141946   \n",
       "1  4.751832        11  121.632547   39.141946  121.626144   39.140281   \n",
       "2  4.751832        11  121.626144   39.140281  121.631219   39.141811   \n",
       "3  4.751832        11  121.631219   39.141811  121.632084   39.146201   \n",
       "4  4.751832        11  121.632084   39.146201  121.631574   39.142231   \n",
       "\n",
       "   grid_distance  urgency  hour  weather_grade_Normal Weather  \\\n",
       "0          377.0     1246    11                             1   \n",
       "1          780.0     1246    11                             1   \n",
       "2          550.0     2462    11                             1   \n",
       "3          707.0     1205    11                             1   \n",
       "4          770.0     1882    11                             1   \n",
       "\n",
       "   weather_grade_Slightly Bad Weather  weather_grade_Very Bad Weather  \n",
       "0                                   0                               0  \n",
       "1                                   0                               0  \n",
       "2                                   0                               0  \n",
       "3                                   0                               0  \n",
       "4                                   0                               0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courier_wave_start_lng</th>\n      <th>courier_wave_start_lat</th>\n      <th>group</th>\n      <th>level</th>\n      <th>speed</th>\n      <th>max_load</th>\n      <th>source_lng</th>\n      <th>source_lat</th>\n      <th>target_lng</th>\n      <th>target_lat</th>\n      <th>grid_distance</th>\n      <th>urgency</th>\n      <th>hour</th>\n      <th>weather_grade_Normal Weather</th>\n      <th>weather_grade_Slightly Bad Weather</th>\n      <th>weather_grade_Very Bad Weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>11</td>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>121.632547</td>\n      <td>39.141946</td>\n      <td>377.0</td>\n      <td>1246</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>11</td>\n      <td>121.632547</td>\n      <td>39.141946</td>\n      <td>121.626144</td>\n      <td>39.140281</td>\n      <td>780.0</td>\n      <td>1246</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>11</td>\n      <td>121.626144</td>\n      <td>39.140281</td>\n      <td>121.631219</td>\n      <td>39.141811</td>\n      <td>550.0</td>\n      <td>2462</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>11</td>\n      <td>121.631219</td>\n      <td>39.141811</td>\n      <td>121.632084</td>\n      <td>39.146201</td>\n      <td>707.0</td>\n      <td>1205</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>11</td>\n      <td>121.632084</td>\n      <td>39.146201</td>\n      <td>121.631574</td>\n      <td>39.142231</td>\n      <td>770.0</td>\n      <td>1882</td>\n      <td>11</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 43
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   courier_wave_start_lng  courier_wave_start_lat         group  level  \\\n",
       "0              121.630558                 39.1409  2.020000e+16      3   \n",
       "1              121.630558                 39.1409  2.020000e+16      3   \n",
       "2              121.630558                 39.1409  2.020000e+16      3   \n",
       "3              121.630558                 39.1409  2.020000e+16      3   \n",
       "4              121.630558                 39.1409  2.020000e+16      3   \n",
       "\n",
       "      speed  max_load  source_lng  source_lat  target_lng  target_lat  \\\n",
       "0  5.535851        11  121.630558   39.140900  121.629930   39.144603   \n",
       "1  5.535851        11  121.629930   39.144603  121.629604   39.150661   \n",
       "2  5.535851        11  121.629604   39.150661  121.629930   39.144603   \n",
       "3  5.535851        11  121.629930   39.144603  121.630544   39.152711   \n",
       "4  5.535851        11  121.630544   39.152711  121.631446   39.142762   \n",
       "\n",
       "   grid_distance  urgency  hour  weather_grade_Normal Weather  \\\n",
       "0          796.0     1776    13                             1   \n",
       "1         1048.0      697    13                             1   \n",
       "2         1019.0     1756    13                             1   \n",
       "3         1198.0      676    13                             1   \n",
       "4         1275.0     2336    14                             1   \n",
       "\n",
       "   weather_grade_Slightly Bad Weather  weather_grade_Very Bad Weather  \n",
       "0                                   0                               0  \n",
       "1                                   0                               0  \n",
       "2                                   0                               0  \n",
       "3                                   0                               0  \n",
       "4                                   0                               0  "
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courier_wave_start_lng</th>\n      <th>courier_wave_start_lat</th>\n      <th>group</th>\n      <th>level</th>\n      <th>speed</th>\n      <th>max_load</th>\n      <th>source_lng</th>\n      <th>source_lat</th>\n      <th>target_lng</th>\n      <th>target_lat</th>\n      <th>grid_distance</th>\n      <th>urgency</th>\n      <th>hour</th>\n      <th>weather_grade_Normal Weather</th>\n      <th>weather_grade_Slightly Bad Weather</th>\n      <th>weather_grade_Very Bad Weather</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>121.630558</td>\n      <td>39.140900</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>796.0</td>\n      <td>1776</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>121.629604</td>\n      <td>39.150661</td>\n      <td>1048.0</td>\n      <td>697</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>121.629604</td>\n      <td>39.150661</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>1019.0</td>\n      <td>1756</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>121.630544</td>\n      <td>39.152711</td>\n      <td>1198.0</td>\n      <td>676</td>\n      <td>13</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>121.630544</td>\n      <td>39.152711</td>\n      <td>121.631446</td>\n      <td>39.142762</td>\n      <td>1275.0</td>\n      <td>2336</td>\n      <td>14</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Scale Necessary Set\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_st = scaler.transform(X_train)\n",
    "X_test_st = scaler.transform(X_test)\n",
    "\n",
    "scaler_p = StandardScaler().fit(X)\n",
    "df_p = scaler_p.transform(df_p)\n",
    "X_st=scaler_p.transform(X)"
   ]
  },
  {
   "source": [
    "# Step 2: Train on different baseline models"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # Logistic Classification\n",
    "# from sklearn.linear_model import LogisticRegression as LogitReg\n",
    "# LR=LogitReg(max_iter=10000).fit(X_train_st,y_train)\n",
    "# prob_pred=LR.predict_proba(X_train_st)\n",
    "# print(prob_pred)\n",
    "\n",
    "# # t=0.5\n",
    "# # y_pred=np.array(list(map(lambda x: int(x>=t), prob_pred[:,1])))\n",
    "# # y_pred\n",
    "\n",
    "# # from sklearn.metrics import auc,roc_curve\n",
    "# # Out-of-Sample\n",
    "# # fpr,tpr,thresholds=roc_curve(y_test,prob_test[:,1])\n",
    "# # roc_auc=auc(fpr,tpr)\n",
    "# # print(\"The out of sample AUC is {:4f}.\".format(roc_auc))\n",
    "# prob_test=LR.predict_proba(X_test_st)\n",
    "# y_pred_test=list(map(lambda x: int(x>=0.7),prob_test[:,1]))\n",
    "# fbeta=fbeta_score(y_test, y_pred_test, beta=0.5)\n",
    "# print('The Fbeta_score for Logistic Classification Model is', fbeta)\n",
    "# # The importance of each feature"
   ]
  },
  {
   "source": [
    "In my previous trials: \n",
    "The Fbeta_score for Logistic Classification Model is 0.6880545634746095"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # Decision Tree\n",
    "# from sklearn.tree import DecisionTreeClassifier,export_graphviz\n",
    "# from sklearn.metrics import accuracy_score\n",
    "# Action_type_tree=DecisionTreeClassifier()\n",
    "# Action_type_tree.fit(X_train_st,y_train)\n",
    "# y_pred=Action_type_tree.predict(X_test_st)\n",
    "# # y_score=Action_type_tree.predict_proba(X_test_st)\n",
    "# # fpr,tpr,threshold= roc_curve(y_test,y_score[:,1])\n",
    "# # roc_auc=auc(fpr,tpr)\n",
    "# fbeta=fbeta_score(y_test, y_pred, beta=0.5)\n",
    "# print('The Fbeta_score for Decision Tree is', fbeta)\n",
    "# # The importance of each feature"
   ]
  },
  {
   "source": [
    "In my previous trials: The Fbeta_score for Decision Tree is 0.7186692799937696"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # KNN Classification\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# Action_Type_knn=KNeighborsClassifier(n_neighbors=100).fit(X_train_st,y_train)\n",
    "# y_pred = Action_Type_knn.predict(X_test_st)\n",
    "# # pred_prob=Action_Type_knn.predict_proba(X_test_st)\n",
    "# # fpr,tpr,threshold=roc_curve(y_test,pred_prob[:,1])\n",
    "# # roc_auc=auc(fpr,tpr)\n",
    "# # print(\"The out-of-sample AUC for KNN is\", roc_auc)\n",
    "# fbeta=fbeta_score(y_test, y_pred, beta=0.5)\n",
    "# print('The Fbeta_score for KNN Classification is', fbeta)\n",
    "# # The importance of each feature\n"
   ]
  },
  {
   "source": [
    "In previous trials:The Fbeta_score for KNN Classification is 0.8083948817076496"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # XgBoost\n",
    "# import xgboost as xgb\n",
    "# data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "# data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "# Action_type_xgbt=xgb.XGBClassifier().fit(X_train_st,y_train)\n",
    "\n",
    "# y_pred=Action_type_xgbt.predict(X_test_st)\n",
    "# fbeta=fbeta_score(y_test, y_pred, beta=0.5)\n",
    "# print('The Fbeta_score for XgBoost is', fbeta)\n",
    "# print(X_train.columns.values)\n",
    "# print('The features importance is shown here:',Action_type_xgbt.feature_importances_ )"
   ]
  },
  {
   "source": [
    "In previous trials: The Fbeta_score for XgBoost is 0.8124462981252886\n",
    "\n",
    "From the Fbeta_score listed above, xgBoost should be the best model. Further fine tune for it."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Step 2(b): Narrow down the feature combination using the best model selected\n",
    "\n",
    "Select the features that have importance > 0.03"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('dataframe_train.csv')\n",
    "df_p=pd.read_csv('dataframe_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['courier_id', 'wave_index', 'tracking_id', 'date', 'group', 'level', 'speed', 'max_load', 'weather_grade', 'aoi_id', 'shop_id', 'id', 'source_type', 'source_tracking_id', 'source_lng', 'source_lat', 'expected_use_time', 'hour']\n"
     ]
    }
   ],
   "source": [
    "# for df\n",
    "columns_all=df.columns.values\n",
    "columns_need=['courier_wave_start_lng','courier_wave_start_lat','target_lng','target_lat','grid_distance','urgency','action_type']\n",
    "\n",
    "columns_to_drop=[]\n",
    "for i in columns_all:\n",
    "    if i not in columns_need:\n",
    "        columns_to_drop.append(i)\n",
    "print(columns_to_drop)\n",
    "df=df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['courier_id', 'wave_index', 'tracking_id', 'date', 'group', 'level', 'speed', 'max_load', 'weather_grade', 'aoi_id', 'shop_id', 'id', 'source_type', 'source_tracking_id', 'source_lng', 'source_lat', 'hour']\n"
     ]
    }
   ],
   "source": [
    "#for df_p\n",
    "columns_all=df_p.columns.values\n",
    "\n",
    "columns_need=['courier_wave_start_lng','courier_wave_start_lat','target_lng','target_lat','grid_distance','urgency','action_type']\n",
    "columns_to_drop=[]\n",
    "for i in columns_all:\n",
    "    if i not in columns_need:\n",
    "        columns_to_drop.append(i)\n",
    "print(columns_to_drop)\n",
    "df_p=df_p.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 509604 entries, 0 to 509603\n",
      "Data columns (total 7 columns):\n",
      " #   Column                  Non-Null Count   Dtype  \n",
      "---  ------                  --------------   -----  \n",
      " 0   courier_wave_start_lng  509604 non-null  float64\n",
      " 1   courier_wave_start_lat  509604 non-null  float64\n",
      " 2   target_lng              509604 non-null  float64\n",
      " 3   target_lat              509604 non-null  float64\n",
      " 4   grid_distance           509604 non-null  float64\n",
      " 5   urgency                 509604 non-null  int64  \n",
      " 6   action_type_PICKUP      509604 non-null  uint8  \n",
      "dtypes: float64(5), int64(1), uint8(1)\n",
      "memory usage: 23.8 MB\n",
      "None\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25468 entries, 0 to 25467\n",
      "Data columns (total 6 columns):\n",
      " #   Column                  Non-Null Count  Dtype  \n",
      "---  ------                  --------------  -----  \n",
      " 0   courier_wave_start_lng  25468 non-null  float64\n",
      " 1   courier_wave_start_lat  25468 non-null  float64\n",
      " 2   target_lng              25468 non-null  float64\n",
      " 3   target_lat              25468 non-null  float64\n",
      " 4   grid_distance           25468 non-null  float64\n",
      " 5   urgency                 25468 non-null  int64  \n",
      "dtypes: float64(5), int64(1)\n",
      "memory usage: 1.2 MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df=pd.get_dummies(df,columns=['action_type'],drop_first=True)\n",
    "print(df.info())\n",
    "print(df_p.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tr_te_split\n",
    "X = df.drop(columns=['action_type_PICKUP'])\n",
    "y = df['action_type_PICKUP'].ravel()\n",
    "X_train, X_test, y_train, y_test = tr_te_split(X, y, test_size=0.3,random_state=0)\n",
    "\n",
    "#Scale Necessary Set\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_st = scaler.transform(X_train)\n",
    "X_test_st = scaler.transform(X_test)\n",
    "\n",
    "scaler_p = StandardScaler().fit(X)\n",
    "df_p = scaler_p.transform(df_p)\n",
    "X_st=scaler_p.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\gzLij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:46:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The Fbeta_score for XgBoost is 0.8428487284676511\n",
      "['courier_wave_start_lng' 'courier_wave_start_lat' 'target_lng'\n",
      " 'target_lat' 'grid_distance' 'urgency']\n",
      "The features importance is shown here: [0.08255818 0.0897366  0.06423002 0.05700229 0.42079422 0.2856787 ]\n"
     ]
    }
   ],
   "source": [
    "# Fit a Baseline Model with all features\n",
    "# XgBoost\n",
    "import xgboost as xgb\n",
    "data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "Action_type_xgbt=xgb.XGBClassifier().fit(X_train_st,y_train)\n",
    "\n",
    "y_pred=Action_type_xgbt.predict(X_test_st)\n",
    "fbeta=fbeta_score(y_test, y_pred, beta=0.5)\n",
    "print('The Fbeta_score for XgBoost is', fbeta)\n",
    "print(X_train.columns.values)\n",
    "print('The features importance is shown here:',Action_type_xgbt.feature_importances_ )"
   ]
  },
  {
   "source": [
    "# Step 3: Fine Tune after the best model and best feature combinations found\n",
    "\n",
    "I tried to use PCA and CV, but none of them give a good result comparing to the simplest method"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\gzLij\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "[18:46:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "The Fbeta_score for XgBoost is 0.9396499026068216\n",
      "['courier_wave_start_lng' 'courier_wave_start_lat' 'target_lng'\n",
      " 'target_lat' 'grid_distance' 'urgency']\n",
      "The features importance is shown here: [0.08957425 0.0890241  0.12085743 0.1237528  0.31945175 0.25733972]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "clf=xgb.XGBClassifier(gamma=2,max_depth=12,learning_rate=1,n_estimators=120)\n",
    "poly_pipe=make_pipeline(clf)\n",
    "Action_type_xgbt=poly_pipe.fit(X_train_st,y_train)\n",
    "y_pred=Action_type_xgbt.predict(X_test_st)\n",
    "fbeta=fbeta_score(y_test, y_pred, beta=0.5)\n",
    "print('The Fbeta_score for XgBoost is', fbeta)\n",
    "print(X_train.columns.values)\n",
    "print('The features importance is shown here:',clf.feature_importances_ )"
   ]
  },
  {
   "source": [
    "Feature Importance Analysis:\n",
    "        \n",
    "        It seems that the source type highly indicates the next action of the courier. Mathmatically, it has at least 1/3 probability of getting the right answer. So it has the highest importance.  "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Step 4: Retrain & Step 5: Predict"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[18:48:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([0, 1, 0, ..., 1, 0, 1], dtype=uint8)"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "data_train=xgb.DMatrix(data=X_st,label=y)\n",
    "\n",
    "Finalized_poly_pipe=make_pipeline(xgb.XGBClassifier(gamma=2,max_depth=12,learning_rate=1,n_estimators=120))\n",
    "Finalized_poly_pipe.fit(X_st,y)\n",
    "prediction=1-Finalized_poly_pipe.predict(df_p)\n",
    "prediction"
   ]
  },
  {
   "source": [
    "# I use 1-Finalized_poly_pipe.predict(df_p) because I got 'action_type_pickup' when I dummy variables. Therefore, I will need to make a change before exporting data to the file."
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 62,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  0\n",
       "count  25468.000000\n",
       "mean       0.498822\n",
       "std        0.500008\n",
       "min        0.000000\n",
       "25%        0.000000\n",
       "50%        0.000000\n",
       "75%        1.000000\n",
       "max        1.000000"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>0</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>25468.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>0.498822</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>0.500008</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>1.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 63
    }
   ],
   "source": [
    "prediction=pd.DataFrame(prediction)\n",
    "prediction.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_write= pd.read_csv('Classification.csv')\n",
    "df_write['action_type_DELIVERY'] = prediction\n",
    "df_write.to_csv(r'Classification_sub.csv', index = False, header=True)"
   ]
  },
  {
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# 2 Regression "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Step 1: Preparing Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import sklearn\n",
    "import scipy as sp\n",
    "%matplotlib inline \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_absolute_error as MAE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 509604 entries, 0 to 509603\nData columns (total 25 columns):\n #   Column                  Non-Null Count   Dtype  \n---  ------                  --------------   -----  \n 0   courier_id              509604 non-null  int64  \n 1   wave_index              509604 non-null  int64  \n 2   tracking_id             509604 non-null  float64\n 3   courier_wave_start_lng  509604 non-null  float64\n 4   courier_wave_start_lat  509604 non-null  float64\n 5   action_type             509604 non-null  object \n 6   date                    509604 non-null  int64  \n 7   group                   509604 non-null  float64\n 8   level                   509604 non-null  int64  \n 9   speed                   509604 non-null  float64\n 10  max_load                509604 non-null  int64  \n 11  weather_grade           509604 non-null  object \n 12  aoi_id                  509604 non-null  object \n 13  shop_id                 509604 non-null  object \n 14  id                      509604 non-null  int64  \n 15  source_type             509604 non-null  object \n 16  source_tracking_id      509604 non-null  float64\n 17  source_lng              509604 non-null  float64\n 18  source_lat              509604 non-null  float64\n 19  target_lng              509604 non-null  float64\n 20  target_lat              509604 non-null  float64\n 21  grid_distance           509604 non-null  float64\n 22  expected_use_time       509604 non-null  int64  \n 23  urgency                 509604 non-null  int64  \n 24  hour                    509604 non-null  int64  \ndtypes: float64(11), int64(9), object(5)\nmemory usage: 97.2+ MB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   courier_id  wave_index   tracking_id  courier_wave_start_lng  \\\n",
       "0    10007871           0  2.100070e+18              121.630997   \n",
       "1    10007871           0  2.100070e+18              121.630997   \n",
       "2    10007871           0  2.100070e+18              121.630997   \n",
       "3    10007871           0  2.100070e+18              121.630997   \n",
       "4    10007871           0  2.100070e+18              121.630997   \n",
       "\n",
       "   courier_wave_start_lat action_type      date         group  level  \\\n",
       "0               39.142343      PICKUP  20200201  2.020020e+16      3   \n",
       "1               39.142343    DELIVERY  20200201  2.020020e+16      3   \n",
       "2               39.142343      PICKUP  20200201  2.020020e+16      3   \n",
       "3               39.142343    DELIVERY  20200201  2.020020e+16      3   \n",
       "4               39.142343      PICKUP  20200201  2.020020e+16      3   \n",
       "\n",
       "      speed  ...  source_type source_tracking_id  source_lng source_lat  \\\n",
       "0  4.751832  ...       ASSIGN       2.100070e+18  121.630997  39.142343   \n",
       "1  4.751832  ...       PICKUP       2.100070e+18  121.632547  39.141946   \n",
       "2  4.751832  ...     DELIVERY       2.100070e+18  121.626144  39.140281   \n",
       "3  4.751832  ...       PICKUP       2.100070e+18  121.631219  39.141811   \n",
       "4  4.751832  ...     DELIVERY       2.100070e+18  121.632084  39.146201   \n",
       "\n",
       "   target_lng target_lat  grid_distance  expected_use_time  urgency  hour  \n",
       "0  121.632547  39.141946          377.0                804     1246    11  \n",
       "1  121.626144  39.140281          780.0                298     1246    11  \n",
       "2  121.631219  39.141811          550.0                545     2462    11  \n",
       "3  121.632084  39.146201          707.0                341     1205    11  \n",
       "4  121.631574  39.142231          770.0                166     1882    11  \n",
       "\n",
       "[5 rows x 25 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courier_id</th>\n      <th>wave_index</th>\n      <th>tracking_id</th>\n      <th>courier_wave_start_lng</th>\n      <th>courier_wave_start_lat</th>\n      <th>action_type</th>\n      <th>date</th>\n      <th>group</th>\n      <th>level</th>\n      <th>speed</th>\n      <th>...</th>\n      <th>source_type</th>\n      <th>source_tracking_id</th>\n      <th>source_lng</th>\n      <th>source_lat</th>\n      <th>target_lng</th>\n      <th>target_lat</th>\n      <th>grid_distance</th>\n      <th>expected_use_time</th>\n      <th>urgency</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10007871</td>\n      <td>0</td>\n      <td>2.100070e+18</td>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>PICKUP</td>\n      <td>20200201</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>...</td>\n      <td>ASSIGN</td>\n      <td>2.100070e+18</td>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>121.632547</td>\n      <td>39.141946</td>\n      <td>377.0</td>\n      <td>804</td>\n      <td>1246</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10007871</td>\n      <td>0</td>\n      <td>2.100070e+18</td>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>DELIVERY</td>\n      <td>20200201</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>...</td>\n      <td>PICKUP</td>\n      <td>2.100070e+18</td>\n      <td>121.632547</td>\n      <td>39.141946</td>\n      <td>121.626144</td>\n      <td>39.140281</td>\n      <td>780.0</td>\n      <td>298</td>\n      <td>1246</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10007871</td>\n      <td>0</td>\n      <td>2.100070e+18</td>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>PICKUP</td>\n      <td>20200201</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>...</td>\n      <td>DELIVERY</td>\n      <td>2.100070e+18</td>\n      <td>121.626144</td>\n      <td>39.140281</td>\n      <td>121.631219</td>\n      <td>39.141811</td>\n      <td>550.0</td>\n      <td>545</td>\n      <td>2462</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10007871</td>\n      <td>0</td>\n      <td>2.100070e+18</td>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>DELIVERY</td>\n      <td>20200201</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>...</td>\n      <td>PICKUP</td>\n      <td>2.100070e+18</td>\n      <td>121.631219</td>\n      <td>39.141811</td>\n      <td>121.632084</td>\n      <td>39.146201</td>\n      <td>707.0</td>\n      <td>341</td>\n      <td>1205</td>\n      <td>11</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10007871</td>\n      <td>0</td>\n      <td>2.100070e+18</td>\n      <td>121.630997</td>\n      <td>39.142343</td>\n      <td>PICKUP</td>\n      <td>20200201</td>\n      <td>2.020020e+16</td>\n      <td>3</td>\n      <td>4.751832</td>\n      <td>...</td>\n      <td>DELIVERY</td>\n      <td>2.100070e+18</td>\n      <td>121.632084</td>\n      <td>39.146201</td>\n      <td>121.631574</td>\n      <td>39.142231</td>\n      <td>770.0</td>\n      <td>166</td>\n      <td>1882</td>\n      <td>11</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 25 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 74
    }
   ],
   "source": [
    "df=pd.read_csv('dataframe_train.csv')\n",
    "df.info()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 509604 entries, 0 to 509603\nData columns (total 28 columns):\n #   Column                              Non-Null Count   Dtype  \n---  ------                              --------------   -----  \n 0   courier_id                          509604 non-null  int64  \n 1   wave_index                          509604 non-null  int64  \n 2   tracking_id                         509604 non-null  float64\n 3   courier_wave_start_lng              509604 non-null  float64\n 4   courier_wave_start_lat              509604 non-null  float64\n 5   date                                509604 non-null  int64  \n 6   group                               509604 non-null  float64\n 7   level                               509604 non-null  int64  \n 8   speed                               509604 non-null  float64\n 9   max_load                            509604 non-null  int64  \n 10  aoi_id                              509604 non-null  object \n 11  shop_id                             509604 non-null  object \n 12  id                                  509604 non-null  int64  \n 13  source_tracking_id                  509604 non-null  float64\n 14  source_lng                          509604 non-null  float64\n 15  source_lat                          509604 non-null  float64\n 16  target_lng                          509604 non-null  float64\n 17  target_lat                          509604 non-null  float64\n 18  grid_distance                       509604 non-null  float64\n 19  expected_use_time                   509604 non-null  int64  \n 20  urgency                             509604 non-null  int64  \n 21  hour                                509604 non-null  int64  \n 22  source_type_DELIVERY                509604 non-null  uint8  \n 23  source_type_PICKUP                  509604 non-null  uint8  \n 24  action_type_PICKUP                  509604 non-null  uint8  \n 25  weather_grade_Normal Weather        509604 non-null  uint8  \n 26  weather_grade_Slightly Bad Weather  509604 non-null  uint8  \n 27  weather_grade_Very Bad Weather      509604 non-null  uint8  \ndtypes: float64(11), int64(9), object(2), uint8(6)\nmemory usage: 88.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df=pd.get_dummies(df,columns=['source_type','action_type','weather_grade'],drop_first=True)\n",
    "df.head()\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['courier_id' 'wave_index' 'tracking_id' 'courier_wave_start_lng'\n 'courier_wave_start_lat' 'date' 'group' 'level' 'speed' 'max_load'\n 'aoi_id' 'shop_id' 'id' 'source_tracking_id' 'source_lng' 'source_lat'\n 'target_lng' 'target_lat' 'grid_distance' 'expected_use_time' 'urgency'\n 'hour' 'source_type_DELIVERY' 'source_type_PICKUP' 'action_type_PICKUP'\n 'weather_grade_Normal Weather' 'weather_grade_Slightly Bad Weather'\n 'weather_grade_Very Bad Weather']\n"
     ]
    }
   ],
   "source": [
    "columns_all=df.columns.values\n",
    "print(columns_all)\n",
    "\n",
    "columns_need=['wave_index','courier_wave_start_lng','courier_wave_start_lat','group','level','grid_distance','urgency','hour','expected_use_time','speed','weather_grade_Slightly Bad Weather','weather_grade_Very Bad Weather','source_type_DELIVERY','source_type_PICKUP','weather_grade_Normal Weather']\n",
    "\n",
    "columns_to_drop=[]\n",
    "for i in columns_all:\n",
    "    if i not in columns_need:\n",
    "        columns_to_drop.append(i)\n",
    "\n",
    "df=df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "source": [
    "Data Choice Analysis:\n",
    "\n",
    "    grid-distance/speed: In the simplest case, Time=Distance/Speed\n",
    "    urgency: Higher urgency may indicate shorter time (the courier may speed up)\n",
    "    hour:Courier are busy in different period of the day. The less busy they are, I assume their deliveries to be faster.\n",
    "    weather_grade: bad weather slow down the speed and thus take longer time to deliver.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prove to be a bad strategy:\n",
    "# df['busy_hour']=np.array((df['hour']>=10) & (df['hour']<=19)).astype(int)\n",
    "# df=df.drop(columns=['hour'])\n",
    "# df[df['busy_hour']==1].info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split as tr_te_split\n",
    "X = df.drop(columns=['expected_use_time'])\n",
    "y = df['expected_use_time'].ravel()\n",
    "X_train, X_test, y_train, y_test = tr_te_split(X, y, test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize both the training and the testing sets.\n",
    "# Using StandardScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train_st = scaler.transform(X_train)\n",
    "X_test_st = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X_train)\n",
    "# X_train_st = scaler.transform(X_train)\n",
    "# X_test_st = scaler.transform(X_test)"
   ]
  },
  {
   "source": [
    "# Train On 4 different Models and See their performances \n",
    "(LR/KNN/TREE/RANDOM FOREST/XGBOOST)"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # Logistic Regression\n",
    "# from sklearn.linear_model import LogisticRegression as LogitReg\n",
    "# LR=LogitReg(max_iter=10000).fit(X_train_st,y_train)\n",
    "# prob_pred=LR.predict_proba(X_train_st)\n",
    "# print(prob_pred)\n",
    "\n",
    "# prob_test=LR.predict_proba(X_test_st)\n",
    "# y_pred_test=list(map(lambda x: int(x>=0.5),prob_test[:,1]))\n",
    "# MAE_score=MAE(y_test, y_pred_test)\n",
    "# print('The MAE score for Logistic Regression Model is', MAE)\n",
    "# # The importance of each feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # KNN Regressor\n",
    "# from sklearn.neighbors import KNeighborsRegressor\n",
    "# EUT_knn=KNeighborsRegressor(n_neighbors=100).fit(X_train_st,y_train)\n",
    "# y_pred=EUT_knn.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# MAE_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # Regression Tree Model\n",
    "# from sklearn.tree import DecisionTreeRegressor\n",
    "# EUT_tree = DecisionTreeRegressor().fit(X_train_st,y_train)\n",
    "# y_pred=EUT_tree.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# MAE_score\n",
    "# # print('The MAE score for Tree Regression Model is', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # XG Boost\n",
    "# import xgboost as xgb\n",
    "# data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "# data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "# xgb_reg=xgb.XGBRegressor()\n",
    "\n",
    "# xgb_reg.fit(X_train_st,y_train)\n",
    "# y_pred=xgb_reg.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# MAE_score\n",
    "# # print('The MAE score for XgBoost Regression Model is', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "201.55847429384917\n['wave_index' 'courier_wave_start_lng' 'courier_wave_start_lat' 'group'\n 'level' 'speed' 'grid_distance' 'urgency' 'hour' 'source_type_DELIVERY'\n 'source_type_PICKUP' 'weather_grade_Normal Weather'\n 'weather_grade_Slightly Bad Weather' 'weather_grade_Very Bad Weather']\nfeature importance:  [0.01206657 0.0053394  0.00683972 0.00314411 0.00309758 0.01142361\n 0.20503186 0.09495062 0.01257664 0.47133318 0.15356338 0.00450212\n 0.00287434 0.01325687]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "\n",
    "xgb_reg=xgb.XGBRegressor(objective='reg:squarederror',colsample_bynode=0.8, gamma=0.001,max_depth=5,n_estimators=20)\n",
    "\n",
    "xgb_reg.fit(X_train_st,y_train)\n",
    "y_pred=xgb_reg.predict(X_test_st)\n",
    "MAE_score=MAE(y_test, y_pred)\n",
    "print(MAE_score)\n",
    "print(X_train.columns.values)\n",
    "print('feature importance: ' ,xgb_reg.feature_importances_)"
   ]
  },
  {
   "source": [
    "Model Analysis:\n",
    "\n",
    "        MAE Score Rank: Logistic Regression > Tree Regressor > Random Forest â‰ˆ KNN > Xgboost\n",
    "        Directly choose from KNN and Xgboost. Xgboost performs the best, meaning that it simulates the original data generating process the best. Then I fine tune of the model on that."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Narrow Features based on their significance in the best baseline model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.read_csv('dataframe_train.csv')\n",
    "# df.info()\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df=pd.get_dummies(df,columns=['source_type','action_type','weather_grade'],drop_first=True)\n",
    "# df.head()\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns_all=df.columns.values\n",
    "# print(columns_all)\n",
    "\n",
    "# columns_need=['wave_index','speed','grid_distance','urgency','hour','source_type_DELIVERY','source_type_PICK_UP','weather_grade_Very Bad Weather','expected_use_time']\n",
    "\n",
    "# columns_to_drop=[]\n",
    "# for i in columns_all:\n",
    "#     if i not in columns_need:\n",
    "#         columns_to_drop.append(i)\n",
    "\n",
    "# df=df.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split as tr_te_split\n",
    "# X = df.drop(columns=['expected_use_time'])\n",
    "# y = df['expected_use_time'].ravel()\n",
    "# X_train, X_test, y_train, y_test = tr_te_split(X, y, test_size=0.3,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Standardize both the training and the testing sets.\n",
    "# # Using StandardScaler\n",
    "# from sklearn.preprocessing import StandardScaler\n",
    "# scaler = StandardScaler().fit(X_train)\n",
    "# X_train_st = scaler.transform(X_train)\n",
    "# X_test_st = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import xgboost as xgb\n",
    "# data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "# data_test=xgb.DMatrix(data=X_test_st,label=y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_reg=xgb.XGBRegressor(objective='reg:squarederror',colsample_bynode=0.8, gamma=0.001,max_depth=5,n_estimators=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# xgb_reg.fit(X_train_st,y_train)\n",
    "# y_pred=xgb_reg.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# print(MAE_score)\n",
    "# print(X_train.columns.values)\n",
    "# print('feature importance: ' ,xgb_reg.feature_importances_)"
   ]
  },
  {
   "source": [
    "This is not as good as the original model, abandon this section"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Fine tune for the Best Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "1. I tried PCA and polynomial features on the baseline model, and find that they did not overperform the baseline model, so \n",
    "\n",
    "\n",
    "2. I decided that I should \"back to normal\". And since using grid_search was too slow (I've tried once), so I finally decided to test on different parameters manually."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # XG Boost\n",
    "# import xgboost as xgb\n",
    "# data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "# data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "\n",
    "# xgb_reg=xgb.XGBRegressor(objective='reg:squarederror',colsample_bynode=0.8, gamma=0.001,max_depth=5,n_estimators=20)\n",
    "\n",
    "# xgb_reg.fit(X_train_st,y_train)\n",
    "# y_pred=xgb_reg.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# MAE_score\n",
    "# # print('The MAE score for XgBoost Regression Model is', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # XG Boost\n",
    "# import xgboost as xgb\n",
    "# data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "# data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "# xgb_reg=xgb.XGBRegressor(objective='reg:squarederror',colsample_bynode=0.8, gamma=0.001,max_depth=6,n_estimators=20)\n",
    "\n",
    "# xgb_reg.fit(X_train_st,y_train)\n",
    "# y_pred=xgb_reg.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# MAE_score\n",
    "# # print('The MAE score for XgBoost Regression Model is', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # XG Boost\n",
    "# import xgboost as xgb\n",
    "# data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "# data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "# xgb_reg=xgb.XGBRegressor(colsample_bynode=0.8, gamma=0.001,max_depth=6,n_estimators=5)\n",
    "\n",
    "# xgb_reg.fit(X_train_st,y_train)\n",
    "# y_pred=xgb_reg.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# MAE_score\n",
    "# # print('The MAE score for XgBoost Regression Model is', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fit a Baseline Model with all features\n",
    "# # XG Boost\n",
    "# import xgboost as xgb\n",
    "# data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "# data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "# xgb_reg=xgb.XGBRegressor(learning_rate=0.01)\n",
    "\n",
    "# xgb_reg.fit(X_train_st,y_train)\n",
    "# y_pred=xgb_reg.predict(X_test_st)\n",
    "# MAE_score=MAE(y_test, y_pred)\n",
    "# MAE_score\n",
    "# # print('The MAE score for XgBoost Regression Model is', MAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "195.42389335326789\n['wave_index' 'courier_wave_start_lng' 'courier_wave_start_lat' 'group'\n 'level' 'speed' 'grid_distance' 'urgency' 'hour' 'source_type_DELIVERY'\n 'source_type_PICKUP' 'weather_grade_Normal Weather'\n 'weather_grade_Slightly Bad Weather' 'weather_grade_Very Bad Weather']\n[1.1109776e-02 1.3143742e-03 1.1016952e-03 3.3782487e-04 3.6354913e-04\n 5.5715553e-03 2.0762073e-01 9.5536508e-02 6.7298920e-03 4.7606575e-01\n 1.8716000e-01 0.0000000e+00 0.0000000e+00 7.0883459e-03]\n"
     ]
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "data_train=xgb.DMatrix(data=X_train_st,label=y_train)\n",
    "data_test=xgb.DMatrix(data=X_test_st,label=y_test)\n",
    "\n",
    "xgb_reg=xgb.XGBRegressor(colsample_bynode=0.8, gamma=0.001,max_depth=6,n_estimators=5)\n",
    "\n",
    "xgb_reg.fit(X_train_st,y_train)\n",
    "y_pred=xgb_reg.predict(X_test_st)\n",
    "MAE_score=MAE(y_test, y_pred)\n",
    "print(MAE_score)\n",
    "print(X_train.columns.values)\n",
    "print(xgb_reg.feature_importances_)"
   ]
  },
  {
   "source": [
    "1 The source type still give a good indication\n",
    "\n",
    "2 It is the 'grid_distance' (it's intuitive because time is postively correlated with distance when speed is set) .  \n",
    "\n",
    "3 \"Very Bad Weather\" and \"hour of the day\" also influence the expected use time as courier may need more time in extreme weather. Also, when they are busy, they tend to spend longer time on each delivery.\n",
    "\n",
    "4 If the weather is slightly bad, it is not that influential when predicting courier's expected use time.\n",
    " "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "# Prediction"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 25468 entries, 0 to 25467\nData columns (total 23 columns):\n #   Column                  Non-Null Count  Dtype  \n---  ------                  --------------  -----  \n 0   courier_id              25468 non-null  int64  \n 1   wave_index              25468 non-null  int64  \n 2   tracking_id             25468 non-null  float64\n 3   courier_wave_start_lng  25468 non-null  float64\n 4   courier_wave_start_lat  25468 non-null  float64\n 5   date                    25468 non-null  int64  \n 6   group                   25468 non-null  float64\n 7   level                   25468 non-null  int64  \n 8   speed                   25468 non-null  float64\n 9   max_load                25468 non-null  int64  \n 10  weather_grade           25468 non-null  object \n 11  aoi_id                  25468 non-null  object \n 12  shop_id                 25468 non-null  object \n 13  id                      25468 non-null  object \n 14  source_type             25464 non-null  object \n 15  source_tracking_id      25468 non-null  float64\n 16  source_lng              25468 non-null  float64\n 17  source_lat              25468 non-null  float64\n 18  target_lng              25468 non-null  float64\n 19  target_lat              25468 non-null  float64\n 20  grid_distance           25468 non-null  float64\n 21  urgency                 25468 non-null  int64  \n 22  hour                    25468 non-null  int64  \ndtypes: float64(11), int64(7), object(5)\nmemory usage: 4.5+ MB\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   courier_id  wave_index   tracking_id  courier_wave_start_lng  \\\n",
       "0    10007871           2  2.100000e+18              121.630558   \n",
       "1    10007871           2  2.100000e+18              121.630558   \n",
       "2    10007871           2  2.100000e+18              121.630558   \n",
       "3    10007871           2  2.100000e+18              121.630558   \n",
       "4    10007871           2  2.100000e+18              121.630558   \n",
       "\n",
       "   courier_wave_start_lat      date         group  level     speed  max_load  \\\n",
       "0                 39.1409  20200228  2.020000e+16      3  5.535851        11   \n",
       "1                 39.1409  20200228  2.020000e+16      3  5.535851        11   \n",
       "2                 39.1409  20200228  2.020000e+16      3  5.535851        11   \n",
       "3                 39.1409  20200228  2.020000e+16      3  5.535851        11   \n",
       "4                 39.1409  20200228  2.020000e+16      3  5.535851        11   \n",
       "\n",
       "   ...      id source_type source_tracking_id  source_lng source_lat  \\\n",
       "0  ...  509790      ASSIGN       2.100000e+18  121.630558  39.140900   \n",
       "1  ...  509791      PICKUP       2.100000e+18  121.629930  39.144603   \n",
       "2  ...  509792    DELIVERY       2.100000e+18  121.629604  39.150661   \n",
       "3  ...  509793      PICKUP       2.100000e+18  121.629930  39.144603   \n",
       "4  ...  509794    DELIVERY       2.100000e+18  121.630544  39.152711   \n",
       "\n",
       "   target_lng  target_lat  grid_distance  urgency  hour  \n",
       "0  121.629930   39.144603          796.0     1776    13  \n",
       "1  121.629604   39.150661         1048.0      697    13  \n",
       "2  121.629930   39.144603         1019.0     1756    13  \n",
       "3  121.630544   39.152711         1198.0      676    13  \n",
       "4  121.631446   39.142762         1275.0     2336    14  \n",
       "\n",
       "[5 rows x 23 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>courier_id</th>\n      <th>wave_index</th>\n      <th>tracking_id</th>\n      <th>courier_wave_start_lng</th>\n      <th>courier_wave_start_lat</th>\n      <th>date</th>\n      <th>group</th>\n      <th>level</th>\n      <th>speed</th>\n      <th>max_load</th>\n      <th>...</th>\n      <th>id</th>\n      <th>source_type</th>\n      <th>source_tracking_id</th>\n      <th>source_lng</th>\n      <th>source_lat</th>\n      <th>target_lng</th>\n      <th>target_lat</th>\n      <th>grid_distance</th>\n      <th>urgency</th>\n      <th>hour</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10007871</td>\n      <td>2</td>\n      <td>2.100000e+18</td>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>20200228</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>...</td>\n      <td>509790</td>\n      <td>ASSIGN</td>\n      <td>2.100000e+18</td>\n      <td>121.630558</td>\n      <td>39.140900</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>796.0</td>\n      <td>1776</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>10007871</td>\n      <td>2</td>\n      <td>2.100000e+18</td>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>20200228</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>...</td>\n      <td>509791</td>\n      <td>PICKUP</td>\n      <td>2.100000e+18</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>121.629604</td>\n      <td>39.150661</td>\n      <td>1048.0</td>\n      <td>697</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>10007871</td>\n      <td>2</td>\n      <td>2.100000e+18</td>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>20200228</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>...</td>\n      <td>509792</td>\n      <td>DELIVERY</td>\n      <td>2.100000e+18</td>\n      <td>121.629604</td>\n      <td>39.150661</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>1019.0</td>\n      <td>1756</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>10007871</td>\n      <td>2</td>\n      <td>2.100000e+18</td>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>20200228</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>...</td>\n      <td>509793</td>\n      <td>PICKUP</td>\n      <td>2.100000e+18</td>\n      <td>121.629930</td>\n      <td>39.144603</td>\n      <td>121.630544</td>\n      <td>39.152711</td>\n      <td>1198.0</td>\n      <td>676</td>\n      <td>13</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>10007871</td>\n      <td>2</td>\n      <td>2.100000e+18</td>\n      <td>121.630558</td>\n      <td>39.1409</td>\n      <td>20200228</td>\n      <td>2.020000e+16</td>\n      <td>3</td>\n      <td>5.535851</td>\n      <td>11</td>\n      <td>...</td>\n      <td>509794</td>\n      <td>DELIVERY</td>\n      <td>2.100000e+18</td>\n      <td>121.630544</td>\n      <td>39.152711</td>\n      <td>121.631446</td>\n      <td>39.142762</td>\n      <td>1275.0</td>\n      <td>2336</td>\n      <td>14</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 99
    }
   ],
   "source": [
    "df_p=pd.read_csv('dataframe_test.csv')\n",
    "df_p.info()\n",
    "df_p.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_p=pd.get_dummies(df_p,columns=['source_type','weather_grade'],drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['courier_id' 'wave_index' 'tracking_id' 'courier_wave_start_lng'\n",
      " 'courier_wave_start_lat' 'date' 'group' 'level' 'speed' 'max_load'\n",
      " 'aoi_id' 'shop_id' 'id' 'source_tracking_id' 'source_lng' 'source_lat'\n",
      " 'target_lng' 'target_lat' 'grid_distance' 'urgency' 'hour'\n",
      " 'source_type_DELIVERY' 'source_type_PICKUP'\n",
      " 'weather_grade_Normal Weather' 'weather_grade_Slightly Bad Weather'\n",
      " 'weather_grade_Very Bad Weather']\n"
     ]
    }
   ],
   "source": [
    "columns_all=df_p.columns.values\n",
    "print(columns_all)\n",
    "\n",
    "columns_need=['wave_index','courier_wave_start_lng','courier_wave_start_lat','group','level','grid_distance','urgency','hour','expected_use_time','speed','weather_grade_Slightly Bad Weather','weather_grade_Very Bad Weather','source_type_DELIVERY','source_type_PICKUP','weather_grade_Normal Weather']\n",
    "columns_to_drop=[]\n",
    "for i in columns_all:\n",
    "    if i not in columns_need:\n",
    "        columns_to_drop.append(i)\n",
    "\n",
    "df_p=df_p.drop(columns=columns_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# We use the mean and standard deviation of the training set to standardize both the training and testing sets.\n",
    "scaler = StandardScaler().fit(X)\n",
    "X_st = scaler.transform(X)\n",
    "df_p=scaler.transform(df_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import MinMaxScaler\n",
    "# scaler=MinMaxScaler()\n",
    "# scaler.fit(X)\n",
    "# X_st = scaler.transform(X)\n",
    "# df_p = scaler.transform(df_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([460.34784, 344.99265, 350.9838 , ..., 154.06786, 429.46686,\n",
       "       615.0924 ], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 104
    }
   ],
   "source": [
    "Finalized_xgbr=xgb.XGBRFRegressor(colsample_bynode=0.8, gamma=0.001,max_depth=6,n_estimators=5).fit(X_st,y)\n",
    "predictions=Finalized_xgbr.predict(df_p)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       order  expected_use_time\n",
       "0          0         460.347839\n",
       "1          1         344.992645\n",
       "2          2         350.983795\n",
       "3          3         360.070068\n",
       "4          4         455.753204\n",
       "...      ...                ...\n",
       "25463  25463         425.058777\n",
       "25464  25464         748.078186\n",
       "25465  25465         154.067856\n",
       "25466  25466         429.466858\n",
       "25467  25467         615.092407\n",
       "\n",
       "[25468 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>order</th>\n      <th>expected_use_time</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>460.347839</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>344.992645</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>350.983795</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>360.070068</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>455.753204</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25463</th>\n      <td>25463</td>\n      <td>425.058777</td>\n    </tr>\n    <tr>\n      <th>25464</th>\n      <td>25464</td>\n      <td>748.078186</td>\n    </tr>\n    <tr>\n      <th>25465</th>\n      <td>25465</td>\n      <td>154.067856</td>\n    </tr>\n    <tr>\n      <th>25466</th>\n      <td>25466</td>\n      <td>429.466858</td>\n    </tr>\n    <tr>\n      <th>25467</th>\n      <td>25467</td>\n      <td>615.092407</td>\n    </tr>\n  </tbody>\n</table>\n<p>25468 rows Ã— 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 105
    }
   ],
   "source": [
    "predictions=pd.DataFrame(predictions)\n",
    "predictions.describe()\n",
    "\n",
    "df_write= pd.read_csv('Regression.csv')\n",
    "df_write['expected_use_time'] = predictions\n",
    "df_write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_write.to_csv(r'Regression_for_sub.csv', index = False, header=True)"
   ]
  }
 ]
}